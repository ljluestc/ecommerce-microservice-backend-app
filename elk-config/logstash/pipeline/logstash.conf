input {
  # Beats input for receiving data from Filebeat
  beats {
    port => 5044
  }

  # TCP input for direct log forwarding from applications
  tcp {
    port => 5000
    codec => json_lines
  }

  # UDP input for high-volume logging
  udp {
    port => 5000
    codec => json_lines
  }
}

filter {
  # Parse timestamp from logs
  if [fields][service] {
    mutate {
      add_tag => [ "microservice" ]
      add_field => { "service_name" => "%{[fields][service]}" }
    }
  }

  # Parse Spring Boot logs
  if [message] =~ /^\d{4}-\d{2}-\d{2}/ {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:log_level} %{NUMBER:pid} --- \[%{DATA:thread}\] %{DATA:logger} : %{GREEDYDATA:log_message}"
      }
    }

    date {
      match => [ "timestamp", "yyyy-MM-dd HH:mm:ss.SSS" ]
    }

    mutate {
      remove_field => [ "timestamp" ]
    }
  }

  # Parse JSON logs from applications
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
    }
  }

  # Extract HTTP request information for API Gateway and services
  if [log_message] =~ /HTTP/ {
    grok {
      match => {
        "log_message" => "HTTP %{WORD:http_method} %{URIPATH:request_path}(?:%{URIPARAM:request_params})? - %{NUMBER:response_code} - %{NUMBER:response_time}ms"
      }
    }
  }

  # Extract database operation information
  if [log_message] =~ /SQL|Database|Query/ {
    mutate {
      add_tag => [ "database" ]
    }
  }

  # Extract error information
  if [log_level] == "ERROR" {
    mutate {
      add_tag => [ "error" ]
    }

    if [log_message] =~ /Exception|Error/ {
      grok {
        match => {
          "log_message" => "%{WORD:exception_type}(?:\: %{GREEDYDATA:exception_message})?"
        }
      }
    }
  }

  # Performance monitoring tags
  if [log_message] =~ /performance|latency|duration/ {
    mutate {
      add_tag => [ "performance" ]
    }
  }

  # Business logic tags based on service
  if [service_name] == "order-service" {
    mutate {
      add_tag => [ "orders" ]
    }
  } else if [service_name] == "payment-service" {
    mutate {
      add_tag => [ "payments" ]
    }
  } else if [service_name] == "user-service" {
    mutate {
      add_tag => [ "users" ]
    }
  } else if [service_name] == "product-service" {
    mutate {
      add_tag => [ "products" ]
    }
  } else if [service_name] == "shipping-service" {
    mutate {
      add_tag => [ "shipping" ]
    }
  }

  # Add environment information
  if ![environment] {
    mutate {
      add_field => { "environment" => "development" }
    }
  }

  # Clean up fields
  mutate {
    remove_field => [ "host", "agent", "ecs", "input" ]
  }
}

output {
  # Send to Elasticsearch with different indices based on log type
  if "error" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "ecommerce-errors-%{+YYYY.MM.dd}"
    }
  } else if "performance" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "ecommerce-performance-%{+YYYY.MM.dd}"
    }
  } else if "database" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "ecommerce-database-%{+YYYY.MM.dd}"
    }
  } else if [service_name] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "ecommerce-%{service_name}-%{+YYYY.MM.dd}"
    }
  } else {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "ecommerce-logs-%{+YYYY.MM.dd}"
    }
  }

  # Debug output (remove in production)
  if [log_level] == "DEBUG" or "_grokparsefailure" in [tags] {
    stdout {
      codec => rubydebug
    }
  }
}